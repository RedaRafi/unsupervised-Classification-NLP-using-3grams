# -*- coding: utf-8 -*-
"""Cosine_similarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y2PtmaHL59OZ1Uyq8ZUyXkPddYY0weSd
"""

import numpy as np
import pandas as pd
import string
import nltk

nltk.download('stopwords')
nltk.download('punkt')

classes_file_path ='/content/drive/MyDrive/Boudi DataSet/classes.csv'
classes = pd.read_csv(classes_file_path,encoding='ISO-8859-1')
dataset_file_path ='/content/drive/MyDrive/Boudi DataSet/dataset.csv'
df = pd.read_csv(dataset_file_path,encoding='ISO-8859-1')

# Shows a sample from classes data frame
classes.head()

# Shows a sample dataset dataframe 
df.head()

# from google.colab import drive
# drive.mount('/content/drive')

from nltk.corpus import stopwords
from nltk import word_tokenize
from string import punctuation
import re
def preprocess_text(text, debug = False):
  if debug: print(f"Original Text:\n\t {text}")
  tokens = word_tokenize(text.lower(), language='french')
  if debug: print(f"After tokenization:\n\t {tokens}")
  tokens = [c for c in tokens if c not in punctuation]
  if debug: print(f"After removing punctuation:\n\t {tokens}")
  tokens = [w for w in tokens if tokens not in stopwords.words('french') and len(w)>0]
  if debug: print(f"After removing stopwords:\n\t {tokens}")
  if debug: print(f"Final results:\n\t {' '.join(tokens)}")
  return " ".join(tokens)

preprocess_text(df.iloc[0,0], debug=False)

classes["preprocessed_appellation"] = classes["appellation"].apply(preprocess_text)
df["preprocessed_intitule"] = df["intitule"].apply(preprocess_text)

all_text = classes["preprocessed_appellation"].tolist() + df["preprocessed_intitule"].tolist()

len(all_text)

# print("A sample from the list all_text: \n\t", all_text[:10])
# print("The last 10 element from all_text list: \n\t", all_text[10:])

from sklearn.feature_extraction.text import TfidfVectorizer
tf_idf = TfidfVectorizer()
# Fitting the tf_idf
tf_idf.fit(all_text)
#Computing tf_idf dataset 
X = tf_idf.transform(df['preprocessed_intitule'])
#computing tf_idf classes
Y = tf_idf.transform(classes['preprocessed_appellation'])
print("Dataset shape: ", X.shape)
print("Classes shape: ", Y.shape)

from sklearn.metrics.pairwise import cosine_similarity
similarity_matrice = cosine_similarity(X, Y)

"""
*   Chaque element de dataset a 10 scores de similarity avec les dix classes

*   Chaque element de dataset on prend la classe la plus similaire en se basant sur la mesure cosine

"""

similarity_matrice.shape

"""# Boucle D'affectation des classe au intitule 

"""

# Boucle pour mieux comprendre le process
classes_list = classes['appellation'].tolist()
intitule_classes = []
for i in similarity_matrice:
  classe_plus_similaire_indice = i.argmax()
  intitule_classes.append(classes_list[classe_plus_similaire_indice])
df['classe'] = intitule_classes
df[['intitule', 'classe']].head(20)

df[['intitule', 'classe']].to_csv("resultats.csv")

